{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capstone - Initial Models\n",
    "### Lawrence Huang\n",
    "##### Instructions\n",
    "Create a new notebook for this assignment.\n",
    "\n",
    "1. Split prepared data from Milestone 1 into training and testing\n",
    "2. Build a decision tree model that detects faulty products\n",
    "3. Build an ensemble model that detects faulty products\n",
    "4. Build an SVM model\n",
    "5. Evaluate all three models\n",
    "6. Describe your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data prepration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:(1567, 591)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1          2          3       4      5         6       7  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "\n",
       "        8       9  ...       581     582     583     584      585     586  \\\n",
       "0  1.5005  0.0162  ...       NaN  0.5005  0.0118  0.0035   2.3630     NaN   \n",
       "1  1.4966 -0.0005  ...  208.2045  0.5019  0.0223  0.0055   4.4447  0.0096   \n",
       "2  1.4436  0.0041  ...   82.8602  0.4958  0.0157  0.0039   3.1745  0.0584   \n",
       "3  1.4882 -0.0124  ...   73.8432  0.4990  0.0103  0.0025   2.0544  0.0202   \n",
       "4  1.5031 -0.0031  ...       NaN  0.4800  0.4766  0.1045  99.3032  0.0202   \n",
       "\n",
       "      587     588       589  label  \n",
       "0     NaN     NaN       NaN     -1  \n",
       "1  0.0201  0.0060  208.2045     -1  \n",
       "2  0.0484  0.0148   82.8602      1  \n",
       "3  0.0149  0.0044   73.8432     -1  \n",
       "4  0.0149  0.0044   73.8432     -1  \n",
       "\n",
       "[5 rows x 591 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data: SECOM manufacturing Data Set from UCI Machine Learning Repository\n",
    "filename_features = 'https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "df = pd.read_csv(filename_features, header=None, sep=' ')\n",
    "filename_label = 'http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "df_label = pd.read_csv(filename_label, header=None, sep= ' ', usecols=[0]) # don't need label timestamp\n",
    "\n",
    "# merge data: add label to features\n",
    "df['label'] = df_label\n",
    "\n",
    "# preview data\n",
    "print('dataset shape:{}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with single value:\n",
      "[5 13 42 49 52 69 97 141 149 178 179 186 189 190 191 192 193 194 226 229\n",
      " 230 231 232 233 234 235 236 237 240 241 242 243 256 257 258 259 260 261\n",
      " 262 263 264 265 266 276 284 313 314 315 322 325 326 327 328 329 330 364\n",
      " 369 370 371 372 373 374 375 378 379 380 381 394 395 396 397 398 399 400\n",
      " 401 402 403 404 414 422 449 450 451 458 461 462 463 464 465 466 481 498\n",
      " 501 502 503 504 505 506 507 508 509 512 513 514 515 528 529 530 531 532\n",
      " 533 534 535 536 537 538]\n",
      "\n",
      "# columns with single value: 116\n"
     ]
    }
   ],
   "source": [
    "# identify zero variance columns with constant/single value \n",
    "cols_zero_var = df.loc[:, df.nunique()==1].columns.values\n",
    "print('Columns with single value:\\n{}'.format(cols_zero_var))\n",
    "print('\\n# columns with single value: {}'.format(len(cols_zero_var)))\n",
    "# drop zero variance columns with constant/single value \n",
    "df.drop(cols_zero_var, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type:\n",
      "float64    474\n",
      "int64        1\n",
      "dtype: int64\n",
      "\n",
      "# missing values/ # of columns:\n",
      "0       53\n",
      "1       80\n",
      "2       84\n",
      "3       20\n",
      "4        9\n",
      "5        3\n",
      "6       57\n",
      "7       20\n",
      "8       12\n",
      "9       15\n",
      "10       4\n",
      "12       4\n",
      "14      16\n",
      "24      38\n",
      "51       8\n",
      "260     12\n",
      "273      8\n",
      "715      4\n",
      "794      4\n",
      "949      4\n",
      "1018    12\n",
      "1341     4\n",
      "1429     4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# handle null/missing values\n",
    "# examine data type: all numeric\n",
    "print('data type:')\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# number of missing values: some columns are missing > 90% of values\n",
    "num_missing = df.isna().sum()\n",
    "print('\\n# missing values/ # of columns:')\n",
    "print(num_missing.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with >50% missing values:\n",
      "[72, 73, 85, 109, 110, 111, 157, 158, 220, 244, 245, 246, 292, 293, 345, 346, 358, 382, 383, 384, 492, 516, 517, 518, 578, 579, 580, 581]\n",
      "\n",
      "# columns with >50% missing values: 28\n"
     ]
    }
   ],
   "source": [
    "# drop columns missing >50%\n",
    "cols_excess_missing = num_missing[num_missing>df.shape[0]/2].index.to_list()\n",
    "print('\\nColumns with >50% missing values:\\n{}'.format(cols_excess_missing))\n",
    "print('\\n# columns with >50% missing values: {}'.format(len(cols_excess_missing)))\n",
    "df.drop(cols_excess_missing, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# missing values before imputation: 10868\n",
      "# missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# impute other columns with missing values\n",
    "# strategy: fill with median or 0. Trying median here.\n",
    "print('# missing values before imputation: {}'.format(df.isna().sum().sum()))\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='constant') # fill with 0\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print('# missing values after imputation: {}'.format(df.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with near-zero variance:\n",
      "[74, 114, 206, 209, 249, 342, 347, 387, 478, 521, 542]\n",
      "\n",
      "# columns with near-zero variance: 11\n"
     ]
    }
   ],
   "source": [
    "# find columns with near-zero variance, with conditions 1 and 2:\n",
    "# 1. few (<10%) unique values relative to the number of samples \n",
    "# 2. large ratio (>19, or >95:5%) of the frequency of the most common value to the frequency of the second most common value\n",
    "top2 = (df.apply(lambda x: pd.Series(x.value_counts().values[:2]))).T\n",
    "cols_nzv = df.columns[(df.nunique()/df.shape[0]<0.1) & (top2[0]/top2[1]>19)].to_list()\n",
    "print('columns with near-zero variance:\\n{}'.format(cols_nzv))\n",
    "print('\\n# columns with near-zero variance: {}'.format(len(cols_nzv)))\n",
    "# drop columns with near-zero variance\n",
    "df.drop(cols_nzv, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape:(1567, 436)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>577</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9509</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>71.9005</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9003</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>9.2721</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5831</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9698</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1          2          3       4         6       7       8  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602   97.6133  0.1242  1.5005   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  102.3433  0.1247  1.4966   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102   95.4878  0.1241  1.4436   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  104.2367  0.1217  1.4882   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.3967  0.1235  1.5031   \n",
       "\n",
       "        9      10  ...      577     582     583     584      585     586  \\\n",
       "0  0.0162 -0.0034  ...  14.9509  0.5005  0.0118  0.0035   2.3630  0.0205   \n",
       "1 -0.0005 -0.0148  ...  10.9003  0.5019  0.0223  0.0055   4.4447  0.0096   \n",
       "2  0.0041  0.0013  ...   9.2721  0.4958  0.0157  0.0039   3.1745  0.0584   \n",
       "3 -0.0124 -0.0033  ...   8.5831  0.4990  0.0103  0.0025   2.0544  0.0202   \n",
       "4 -0.0031 -0.0072  ...  10.9698  0.4800  0.4766  0.1045  99.3032  0.0202   \n",
       "\n",
       "      587     588       589  label  \n",
       "0  0.0148  0.0046   71.9005   -1.0  \n",
       "1  0.0201  0.0060  208.2045   -1.0  \n",
       "2  0.0484  0.0148   82.8602    1.0  \n",
       "3  0.0149  0.0044   73.8432   -1.0  \n",
       "4  0.0149  0.0044   73.8432   -1.0  \n",
       "\n",
       "[5 rows x 436 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view cleaned and preprocessed dataframe\n",
    "print('dataset shape:{}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Split prepared data from Milestone 1 into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:\n",
      "[0 1 2 3 4 6 7 8 9 10 11 12 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 45 46 47 48 50 51 53 54 55\n",
      " 56 57 58 59 60 61 62 63 64 65 66 67 68 70 71 75 76 77 78 79 80 81 82 83\n",
      " 84 86 87 88 89 90 91 92 93 94 95 96 98 99 100 101 102 103 104 105 106 107\n",
      " 108 112 113 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 140 142 143 144 145 146 147 148\n",
      " 150 151 152 153 154 155 156 159 160 161 162 163 164 165 166 167 168 169\n",
      " 170 171 172 173 174 175 176 177 180 181 182 183 184 185 187 188 195 196\n",
      " 197 198 199 200 201 202 203 204 205 207 208 210 211 212 213 214 215 216\n",
      " 217 218 219 221 222 223 224 225 227 228 238 239 247 248 250 251 252 253\n",
      " 254 255 267 268 269 270 271 272 273 274 275 277 278 279 280 281 282 283\n",
      " 285 286 287 288 289 290 291 294 295 296 297 298 299 300 301 302 303 304\n",
      " 305 306 307 308 309 310 311 312 316 317 318 319 320 321 323 324 331 332\n",
      " 333 334 335 336 337 338 339 340 341 343 344 348 349 350 351 352 353 354\n",
      " 355 356 357 359 360 361 362 363 365 366 367 368 376 377 385 386 388 389\n",
      " 390 391 392 393 405 406 407 408 409 410 411 412 413 415 416 417 418 419\n",
      " 420 421 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438\n",
      " 439 440 441 442 443 444 445 446 447 448 452 453 454 455 456 457 459 460\n",
      " 467 468 469 470 471 472 473 474 475 476 477 479 480 482 483 484 485 486\n",
      " 487 488 489 490 491 493 494 495 496 497 499 500 510 511 519 520 522 523\n",
      " 524 525 526 527 539 540 541 543 544 545 546 547 548 549 550 551 552 553\n",
      " 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571\n",
      " 572 573 574 575 576 577 582 583 584 585 586 587 588 589]\n",
      "\n",
      "# features at start: 435\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "# stratify to ensure minority class representation in both sets\n",
    "y = df['label'] # label\n",
    "X = df.loc[:, ~df.columns.isin(['label'])] # features, start with all but the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=8)\n",
    "print('features:\\n{}'.format(X.columns.values))\n",
    "print('\\n# features at start: {}'.format(len(X.columns.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize numeric columns (z-score)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle class imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail rate: 6.6%\n"
     ]
    }
   ],
   "source": [
    "# plot distribution of label; check for imbalanced classes\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "sns.countplot(x='label', data=df, ax=ax)\n",
    "plt.title('Distribution of label\\n-1:pass, 1: fail')\n",
    "plt.show()\n",
    "print('fail rate: {:.1f}%'.format(100*df['label'].value_counts()[1]/len(df['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label counts before SMOTE:\n",
      "-1.0    1170\n",
      " 1.0      83\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Label counts after SMOTE:\n",
      " 1.0    1170\n",
      "-1.0    1170\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SMOTE was used to oversample the minority class\n",
    "# By oversampling only on the training data, none of the information in the test data was being used to create synthetic observations. \n",
    "# Therefore, no information will bleed from training to testing.  \n",
    "sm = SMOTE(random_state=1) # sampling strategy = resample all classes but the majority class\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "X_train_res = pd.DataFrame(data=X_train_res, columns=X_train.columns)\n",
    "y_train_res = pd.Series(y_train_res)\n",
    "\n",
    "print('\\nLabel counts before SMOTE:')\n",
    "print(y_train.value_counts())\n",
    "print('\\nLabel counts after SMOTE:')\n",
    "print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply feature selection techniques to reduce dimensionality of data\n",
    "Use filtering methods based on Mutual information score or ANOVA F-value between label/feature to compare the same set of selected features across multiple classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select k best features based on mutual information score (k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features:\n",
      "[104, 121, 123, 124, 131, 143, 155, 166, 167, 219, 238, 239, 278, 288, 357, 366, 368, 376, 377, 584]\n",
      "\n",
      "# selected features: 20\n"
     ]
    }
   ],
   "source": [
    "# select k best features based on mutual information score\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=20).fit(X_train_res, y_train_res) \n",
    "# selected features\n",
    "mi_cols = X_train_res.columns[selector.get_support()].to_list()\n",
    "print('selected features:\\n{}'.format(mi_cols))\n",
    "print('\\n# selected features: {}'.format(len(mi_cols)))\n",
    "X_train_mi = pd.DataFrame(selector.transform(X_train_res), columns=mi_cols)\n",
    "X_test_mi = pd.DataFrame(selector.transform(X_test), columns=mi_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select k best features based on ANOVA F-value (k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "[14, 28, 59, 70, 78, 79, 103, 121, 122, 124, 125, 127, 129, 130, 183, 247, 280, 319, 455, 510]\n",
      "\n",
      "# selected features: 20\n"
     ]
    }
   ],
   "source": [
    "# select k best features based on ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k=20).fit(X_train_res, y_train_res) \n",
    "# selected features\n",
    "f_cols = X_train_res.columns[selector.get_support()].to_list()\n",
    "print('Selected features:\\n{}'.format(f_cols))\n",
    "print('\\n# selected features: {}'.format(len(f_cols)))\n",
    "X_train_f = pd.DataFrame(selector.transform(X_train_res), columns=f_cols)\n",
    "X_test_f = pd.DataFrame(selector.transform(X_test), columns=f_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Build a decision tree model that detects faulty products<a name=\"DT\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default decision tree, no additional feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 435\n",
      "Mean CV recall (Class 1): 0.946\n",
      "\n",
      "Confusion Matrix:\n",
      "[[269  24]\n",
      " [ 13   8]]\n",
      "\n",
      "TP, TN, FP, FN: 8 , 269 , 24 , 13\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.92      0.94       293\n",
      "         1.0       0.25      0.38      0.30        21\n",
      "\n",
      "    accuracy                           0.88       314\n",
      "   macro avg       0.60      0.65      0.62       314\n",
      "weighted avg       0.91      0.88      0.89       314\n",
      "\n",
      "\n",
      "Tree depth: 29, # leaves: 87\n"
     ]
    }
   ],
   "source": [
    "# default gini tree\n",
    "clf_tree = DecisionTreeClassifier(random_state=8)\n",
    "clf_tree.fit(X_train_res, y_train_res)\n",
    "print('# features: {}'.format(X_train_res.shape[1]))\n",
    "cv_scores = cross_val_score(clf_tree, X_train_res, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_tree = clf_tree.predict(X_test)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_tree)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_tree).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "# tree depth and # leaves\n",
    "print('\\nTree depth: {}, # leaves: {}'.format(clf_tree.get_depth(), clf_tree.get_n_leaves()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default decision tree, 20 selected features by mutual information score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "Mean CV recall (Class 1): 0.870\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245  48]\n",
      " [ 17   4]]\n",
      "\n",
      "TP, TN, FP, FN: 4 , 245 , 48 , 17\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.84      0.88       293\n",
      "         1.0       0.08      0.19      0.11        21\n",
      "\n",
      "    accuracy                           0.79       314\n",
      "   macro avg       0.51      0.51      0.50       314\n",
      "weighted avg       0.88      0.79      0.83       314\n",
      "\n",
      "\n",
      "Tree depth: 25, # leaves: 204\n"
     ]
    }
   ],
   "source": [
    "# default gini tree\n",
    "clf_tree = DecisionTreeClassifier(random_state=8)\n",
    "clf_tree.fit(X_train_mi, y_train_res)\n",
    "print('# features: {}'.format(X_train_mi.shape[1]))\n",
    "cv_scores = cross_val_score(clf_tree, X_train_mi, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_tree = clf_tree.predict(X_test_mi)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_tree)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_tree).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "# tree depth and # leaves\n",
    "print('\\nTree depth: {}, # leaves: {}'.format(clf_tree.get_depth(), clf_tree.get_n_leaves()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default decision tree, 20 selected features by ANOVA F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "Mean CV recall (Class 1): 0.921\n",
      "\n",
      "Confusion Matrix:\n",
      "[[260  33]\n",
      " [ 14   7]]\n",
      "\n",
      "TP, TN, FP, FN: 7 , 260 , 33 , 14\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.89      0.92       293\n",
      "         1.0       0.17      0.33      0.23        21\n",
      "\n",
      "    accuracy                           0.85       314\n",
      "   macro avg       0.56      0.61      0.57       314\n",
      "weighted avg       0.90      0.85      0.87       314\n",
      "\n",
      "\n",
      "Tree depth: 29, # leaves: 175\n"
     ]
    }
   ],
   "source": [
    "# default gini tree\n",
    "clf_tree = DecisionTreeClassifier(random_state=8)\n",
    "clf_tree.fit(X_train_f, y_train_res)\n",
    "print('# features: {}'.format(X_train_f.shape[1]))\n",
    "cv_scores = cross_val_score(clf_tree, X_train_f, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_tree = clf_tree.predict(X_test_f)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_tree)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_tree).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "# tree depth and # leaves\n",
    "print('\\nTree depth: {}, # leaves: {}'.format(clf_tree.get_depth(), clf_tree.get_n_leaves()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preliminary results:\n",
    "The default decision tree with no additional feature selection or model using 20 selected features by ANOVA F-value produced better results, as assessed by recall of Class 1 on the test set, compared to the model using 20 selected features by Mutual Information score.\n",
    "\n",
    "Will try tuning the best 2 models (1: no additional feature selection and 2: 20 selected features by ANOVA F-value) to see if recall of Class 1 could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned decision tree, no additional feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following hyperparameters were tuned:\n",
      "['max_leaf_nodes', 'max_depth', 'min_samples_leaf', 'min_samples_split']\n"
     ]
    }
   ],
   "source": [
    "# decision tree with tuned hyperparameters\n",
    "# grid search parameters\n",
    "parameters = [{#'criterion': ['gini', 'entropy'], # use gini\n",
    "               'max_leaf_nodes': range(20, 201, 20),\n",
    "               'max_depth': range(8, 33, 4),\n",
    "               'min_samples_leaf': range(1,7),\n",
    "               'min_samples_split' : range(2,6)\n",
    "              }]\n",
    "print('The following hyperparameters were tuned:\\n{}'.format(list(parameters[0].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1680 candidates, totalling 5040 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5040 out of 5040 | elapsed:  8.0min finished\n"
     ]
    }
   ],
   "source": [
    "# grid search, fit and predict with best estimator\n",
    "gs_tree = GridSearchCV(estimator=DecisionTreeClassifier(random_state=8), \n",
    "                       param_grid=parameters, iid=False, cv=3, scoring='recall', n_jobs=-1, verbose=1)\n",
    "gs_tree.fit(X_train_res, y_train_res)\n",
    "y_pred_gstree = gs_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 435\n",
      "\n",
      "Best hyperparameters:\n",
      "{'max_depth': 8, 'max_leaf_nodes': 60, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Best tuned estimator:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
      "                       max_features=None, max_leaf_nodes=60,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=8, splitter='best')\n",
      "\n",
      "Best mean CV score: 0.952\n",
      "\n",
      "Features with non-zero importance: 42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[243  50]\n",
      " [ 12   9]]\n",
      "\n",
      "TP, TN, FP, FN: 9 , 243 , 50 , 12\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.83      0.89       293\n",
      "         1.0       0.15      0.43      0.23        21\n",
      "\n",
      "    accuracy                           0.80       314\n",
      "   macro avg       0.55      0.63      0.56       314\n",
      "weighted avg       0.90      0.80      0.84       314\n",
      "\n",
      "\n",
      "Tuned tree depth: 8, # leaves: 45\n"
     ]
    }
   ],
   "source": [
    "print('# features: {}'.format(X_train_res.shape[1]))\n",
    "\n",
    "# best tuned decision tree and hyperparameters\n",
    "print('\\nBest hyperparameters:\\n{}'.format(gs_tree.best_params_))\n",
    "print('\\nBest tuned estimator:\\n{}'.format(gs_tree.best_estimator_))\n",
    "print('\\nBest mean CV score: {:.3f}'.format(gs_tree.best_score_))\n",
    "print('\\nFeatures with non-zero importance: {}'.format((gs_tree.best_estimator_.feature_importances_!=0).sum()))\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_gstree)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_gstree).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_gstree))\n",
    "\n",
    "# tree depth and # leaves\n",
    "print('\\nTuned tree depth: {}, # leaves: {}'.format(gs_tree.best_estimator_.get_depth(), gs_tree.best_estimator_.get_n_leaves()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned decision tree, 20 selected features by ANOVA F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following hyperparameters were tuned:\n",
      "['max_leaf_nodes', 'max_depth', 'min_samples_leaf', 'min_samples_split']\n"
     ]
    }
   ],
   "source": [
    "# decision tree with tuned hyperparameters\n",
    "# grid search parameters\n",
    "parameters = [{#'criterion': ['gini', 'entropy'], # use gini\n",
    "               'max_leaf_nodes': range(20, 201, 20),\n",
    "               'max_depth': range(8, 33, 4),\n",
    "               'min_samples_leaf': range(1,7),\n",
    "               'min_samples_split' : range(2,6)\n",
    "              }]\n",
    "print('The following hyperparameters were tuned:\\n{}'.format(list(parameters[0].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1680 candidates, totalling 5040 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1696 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4196 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 5040 out of 5040 | elapsed:   22.8s finished\n"
     ]
    }
   ],
   "source": [
    "# grid search, fit and predict with best estimator\n",
    "gs_tree = GridSearchCV(estimator=DecisionTreeClassifier(random_state=8), \n",
    "                       param_grid=parameters, iid=False, cv=3, scoring='recall', n_jobs=-1, verbose=1)\n",
    "gs_tree.fit(X_train_f, y_train_res)\n",
    "y_pred_gstree = gs_tree.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "\n",
      "Best hyperparameters:\n",
      "{'max_depth': 12, 'max_leaf_nodes': 100, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "\n",
      "Best tuned estimator:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
      "                       max_features=None, max_leaf_nodes=100,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=8, splitter='best')\n",
      "\n",
      "Best mean CV score: 0.927\n",
      "\n",
      "Features with non-zero importance: 19\n",
      "\n",
      "Confusion Matrix:\n",
      "[[242  51]\n",
      " [ 13   8]]\n",
      "\n",
      "TP, TN, FP, FN: 8 , 242 , 51 , 13\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.83      0.88       293\n",
      "         1.0       0.14      0.38      0.20        21\n",
      "\n",
      "    accuracy                           0.80       314\n",
      "   macro avg       0.54      0.60      0.54       314\n",
      "weighted avg       0.89      0.80      0.84       314\n",
      "\n",
      "\n",
      "Tuned tree depth: 12, # leaves: 97\n"
     ]
    }
   ],
   "source": [
    "print('# features: {}'.format(X_train_f.shape[1]))\n",
    "\n",
    "# best tuned decision tree and hyperparameters\n",
    "print('\\nBest hyperparameters:\\n{}'.format(gs_tree.best_params_))\n",
    "print('\\nBest tuned estimator:\\n{}'.format(gs_tree.best_estimator_))\n",
    "print('\\nBest mean CV score: {:.3f}'.format(gs_tree.best_score_))\n",
    "print('\\nFeatures with non-zero importance: {}'.format((gs_tree.best_estimator_.feature_importances_!=0).sum()))\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_gstree)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_gstree).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_gstree))\n",
    "\n",
    "# tree depth and # leaves\n",
    "print('\\nTuned tree depth: {}, # leaves: {}'.format(gs_tree.best_estimator_.get_depth(), gs_tree.best_estimator_.get_n_leaves()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above (tuned decision tree with feature selection using ANOVA F-value) for comparison across models\n",
    "precision_t, recall_t, fscore_t, support_t = precision_recall_fscore_support(y_test, y_pred_gstree)\n",
    "accuracy_t = accuracy_score(y_test, y_pred_gstree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary for decision tree model:\n",
    "<ul>\n",
    "    <li>The default decision tree model with no additional feature selection produced the best Class 1 recall (and also the best overall accuracy), compared to 20-feature subsets selected by Mutual Information score or ANOVA F-value</li>\n",
    "    <li>After hyperparameter tuning, recall for Class 1 improved slightly in both the model with no additional feature selection and the model with feature selection by ANOVA F-value</li>\n",
    "    <li>After hyperparameter tuning, the model with feature selection by ANOVA F-value produced very similar results compared to the model with no additional feature selection, despite using ~45% of the features for splitting: 19 (out of 20) compared to 42 (out of 435) features with non-zero importance, respectively</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Build an ensemble model that detects faulty products<a name=\"RF\"></a>\n",
    "Will construct a random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default random forest, no additional feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 435\n",
      "Mean CV recall (Class 1): 0.985\n",
      "\n",
      "Confusion Matrix:\n",
      "[[290   3]\n",
      " [ 19   2]]\n",
      "\n",
      "TP, TN, FP, FN: 2 , 290 , 3 , 19\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.99      0.96       293\n",
      "         1.0       0.40      0.10      0.15        21\n",
      "\n",
      "    accuracy                           0.93       314\n",
      "   macro avg       0.67      0.54      0.56       314\n",
      "weighted avg       0.90      0.93      0.91       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=40, random_state=8) # where 40 ~= sqrt of # observations\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "print('# features: {}'.format(X_train_res.shape[1]))\n",
    "cv_scores = cross_val_score(rf, X_train_res, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_rf)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try again using hyperparameters from the decision tree model above (that had the same feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 435\n",
      "Mean CV recall (Class 1): 0.985\n",
      "\n",
      "Confusion Matrix:\n",
      "[[276  17]\n",
      " [ 18   3]]\n",
      "\n",
      "TP, TN, FP, FN: 3 , 276 , 17 , 18\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.94      0.94       293\n",
      "         1.0       0.15      0.14      0.15        21\n",
      "\n",
      "    accuracy                           0.89       314\n",
      "   macro avg       0.54      0.54      0.54       314\n",
      "weighted avg       0.89      0.89      0.89       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest, using tuned decision tree hyperparameters above for no additional feature selection\n",
    "rf = RandomForestClassifier(n_estimators=40, random_state=8, # where 40 ~= sqrt of # observations\n",
    "                           max_depth=8, max_leaf_nodes=60, min_samples_leaf=1, min_samples_split=2) \n",
    "rf.fit(X_train_res, y_train_res)\n",
    "print('# features: {}'.format(X_train_res.shape[1]))\n",
    "cv_scores = cross_val_score(rf, X_train_res, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_rf)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default random forest, 20 features by mutual information score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "Mean CV recall (Class 1): 0.938\n",
      "\n",
      "Confusion Matrix:\n",
      "[[284   9]\n",
      " [ 20   1]]\n",
      "\n",
      "TP, TN, FP, FN: 1 , 284 , 9 , 20\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.97      0.95       293\n",
      "         1.0       0.10      0.05      0.06        21\n",
      "\n",
      "    accuracy                           0.91       314\n",
      "   macro avg       0.52      0.51      0.51       314\n",
      "weighted avg       0.88      0.91      0.89       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=40, random_state=8) # where 40 ~= sqrt of # observations\n",
    "rf.fit(X_train_mi, y_train_res)\n",
    "print('# features: {}'.format(X_train_mi.shape[1]))\n",
    "cv_scores = cross_val_score(rf, X_train_mi, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf.predict(X_test_mi)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_rf)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default random forest, 20 features by ANOVA F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "Mean CV recall (Class 1): 0.962\n",
      "\n",
      "Confusion Matrix:\n",
      "[[277  16]\n",
      " [ 16   5]]\n",
      "\n",
      "TP, TN, FP, FN: 5 , 277 , 16 , 16\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.95      0.95       293\n",
      "         1.0       0.24      0.24      0.24        21\n",
      "\n",
      "    accuracy                           0.90       314\n",
      "   macro avg       0.59      0.59      0.59       314\n",
      "weighted avg       0.90      0.90      0.90       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(n_estimators=40, random_state=8) # where 40 ~= sqrt of # observations\n",
    "rf.fit(X_train_f, y_train_res)\n",
    "print('# features: {}'.format(X_train_f.shape[1]))\n",
    "cv_scores = cross_val_score(rf, X_train_f, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf.predict(X_test_f)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_rf)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try again using hyperparameters from the decision tree model above (that had the same feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "Mean CV recall (Class 1): 0.960\n",
      "\n",
      "Confusion Matrix:\n",
      "[[272  21]\n",
      " [ 16   5]]\n",
      "\n",
      "TP, TN, FP, FN: 5 , 272 , 21 , 16\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.93      0.94       293\n",
      "         1.0       0.19      0.24      0.21        21\n",
      "\n",
      "    accuracy                           0.88       314\n",
      "   macro avg       0.57      0.58      0.57       314\n",
      "weighted avg       0.89      0.88      0.89       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest, using tuned decision tree hyperparameters above for feature selection using ANOVA F-value\n",
    "rf = RandomForestClassifier(n_estimators=40, random_state=8, # where 40 ~= sqrt of # observations\n",
    "                           max_depth=12, max_leaf_nodes=100, min_samples_leaf=1, min_samples_split=4) \n",
    "rf.fit(X_train_f, y_train_res)\n",
    "print('# features: {}'.format(X_train_f.shape[1]))\n",
    "cv_scores = cross_val_score(rf, X_train_f, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf.predict(X_test_f)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_rf)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminary results:\n",
    "The random forest model with 20 features by ANOVA F-value produced the best results, as assessed by the recall of Class 1 on the test set. By this metric, the other random forest models (with no additional feature selection and feature selection using Mutual Information score) performed worse than the decision tree models.\n",
    "\n",
    "Will try tuning the best random forest model (with 20 features by ANOVA F-value) to see if recall of Class 1 could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned random forest, 20 features by ANOVA F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following hyperparameters were tuned:\n",
      "['n_estimators', 'max_leaf_nodes', 'max_depth', 'min_samples_leaf', 'min_samples_split']\n"
     ]
    }
   ],
   "source": [
    "# grid search parameters\n",
    "# use gini trees\n",
    "parameters = [{'n_estimators': [20, 40, 100, 200], # where 40 ~= sqrt of # observations\n",
    "               'max_leaf_nodes': range(20, 201, 20),\n",
    "               'max_depth': range(8, 33, 4),\n",
    "               'min_samples_leaf': range(1,6),\n",
    "               'min_samples_split' : range(2,6)\n",
    "              }]\n",
    "print('The following hyperparameters were tuned:\\n{}'.format(list(parameters[0].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5600 candidates, totalling 16800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 410 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 910 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1610 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2510 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3578 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4228 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4978 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6778 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7828 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8978 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10228 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11578 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 13028 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14578 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16228 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16800 out of 16800 | elapsed: 15.2min finished\n"
     ]
    }
   ],
   "source": [
    "# grid search, fit with best estimator\n",
    "gs_rf = GridSearchCV(estimator=RandomForestClassifier(random_state=8), \n",
    "                     param_grid=parameters, iid=False, cv=3, scoring='recall', n_jobs=-1, verbose=1)\n",
    "gs_rf.fit(X_train_f, y_train_res)\n",
    "y_pred_gsrf = gs_rf.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "\n",
      "Best hyperparameters:\n",
      "{'max_depth': 16, 'max_leaf_nodes': 120, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Best tuned estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=16, max_features='auto', max_leaf_nodes=120,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "Best mean CV score: 0.970\n",
      "\n",
      "Confusion Matrix:\n",
      "[[275  18]\n",
      " [ 14   7]]\n",
      "\n",
      "TP, TN, FP, FN: 7 , 275 , 18 , 14\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.94      0.95       293\n",
      "         1.0       0.28      0.33      0.30        21\n",
      "\n",
      "    accuracy                           0.90       314\n",
      "   macro avg       0.62      0.64      0.62       314\n",
      "weighted avg       0.91      0.90      0.90       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# features: {}'.format(X_train_f.shape[1]))\n",
    "\n",
    "# best tuned decision random forest hyperparameters\n",
    "print('\\nBest hyperparameters:\\n{}'.format(gs_rf.best_params_))\n",
    "print('\\nBest tuned estimator:\\n{}'.format(gs_rf.best_estimator_))\n",
    "print('\\nBest mean CV score: {:.3f}'.format(gs_rf.best_score_))\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_gsrf)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_gsrf).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_gsrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above (tuned random forest with feature selection using ANOVA F-value) for comparison across models\n",
    "precision_r, recall_r, fscore_r, support_r = precision_recall_fscore_support(y_test, y_pred_gsrf)\n",
    "accuracy_r = accuracy_score(y_test, y_pred_gsrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary for random forest model:\n",
    "<ul>\n",
    "    <li>The random forest model with feature selection using ANOVA F-value produced the best results, as assessed by recall of Class 1 on the test set; hyperparameter tuning further improved recall</li>\n",
    "    <li>The other random forest models (with no additional feature selection and feature selection using Mutual Information score) performed worse than the decision tree models, as assessed by recall of Class 1 on test set, possibly due to imbalanced classes in the test set (SMOTE was applied only to the training data)</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Build an SVM model<a name=\"SVM\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default SVM (SVC), no additional feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 435\n",
      "Mean CV recall (Class 1): 0.997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[290   3]\n",
      " [ 21   0]]\n",
      "\n",
      "TP, TN, FP, FN: 0 , 290 , 3 , 21\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.99      0.96       293\n",
      "         1.0       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.92       314\n",
      "   macro avg       0.47      0.49      0.48       314\n",
      "weighted avg       0.87      0.92      0.90       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default SVC\n",
    "svc = SVC(gamma='auto', random_state=8)\n",
    "svc.fit(X_train_res, y_train_res)\n",
    "print('# features: {}'.format(X_train_res.shape[1]))\n",
    "cv_scores = cross_val_score(svc, X_train_res, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_svc)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svc).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default SVM (SVC), 20 features by mutual information score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "Mean CV recall (Class 1): 0.897\n",
      "\n",
      "Confusion Matrix:\n",
      "[[233  60]\n",
      " [ 17   4]]\n",
      "\n",
      "TP, TN, FP, FN: 4 , 233 , 60 , 17\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.80      0.86       293\n",
      "         1.0       0.06      0.19      0.09        21\n",
      "\n",
      "    accuracy                           0.75       314\n",
      "   macro avg       0.50      0.49      0.48       314\n",
      "weighted avg       0.87      0.75      0.81       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default SVC\n",
    "svc = SVC(gamma='auto', random_state=8)\n",
    "svc.fit(X_train_mi, y_train_res)\n",
    "print('# features: {}'.format(X_train_mi.shape[1]))\n",
    "cv_scores = cross_val_score(svc, X_train_mi, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_svc = svc.predict(X_test_mi)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_svc)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svc).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default SVM (SVC), 20 features by ANOVA F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV recall (Class 1): 0.947\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250  43]\n",
      " [ 14   7]]\n",
      "\n",
      "TP, TN, FP, FN: 7 , 250 , 43 , 14\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.85      0.90       293\n",
      "         1.0       0.14      0.33      0.20        21\n",
      "\n",
      "    accuracy                           0.82       314\n",
      "   macro avg       0.54      0.59      0.55       314\n",
      "weighted avg       0.89      0.82      0.85       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default SVC\n",
    "svc = SVC(gamma='auto', random_state=8)\n",
    "svc.fit(X_train_f, y_train_res)\n",
    "cv_scores = cross_val_score(svc, X_train_f, y_train_res, cv=3, scoring='recall')\n",
    "print('Mean CV recall (Class 1): {:.3f}'.format(cv_scores.mean()))\n",
    "\n",
    "# prediction\n",
    "y_pred_svc = svc.predict(X_test_f)\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_svc)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svc).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminary results:\n",
    "Using the default SVM (SVC) with feature selection using ANOVA F-value produced the best result, as assessed by the recall of Class 1 on the test set. Using all features did not work (no true positives).\n",
    "\n",
    "Will try tuning the SVC using feature selection by ANOVA F-value to see if recall of Class 1 could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned SVM (SVC), 20 features by ANOVA F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following hyperparameters were tuned:\n",
      "['C', 'kernel', 'gamma']\n"
     ]
    }
   ],
   "source": [
    "# grid search parameters\n",
    "parameters = [\n",
    "    {'C': [1e-1, 1e0, 1e1, 1e2, 1e3, 1e4], 'kernel': ['rbf', 'sigmoid'], 'gamma': [0.005, 'auto', 0.5, 1, 'scale']},\n",
    "#     {'C': [1e-1, 1e0, 1e1, 1e2, 1e3, 1e4], 'kernel': ['poly'], 'gamma': [0.005, 'auto', 0.5, 1, 'scale'], 'degree': [2,3,4]},\n",
    "    {'C': [1e-1, 1e0, 1e1, 1e2, 1e3, 1e4], 'kernel': ['linear']}\n",
    "]\n",
    "print('The following hyperparameters were tuned:\\n{}'.format(list(parameters[0].keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "From the first run, the best hyperparameters were: {'C': 0.1, 'degree': 2, 'gamma': 0.005, 'kernel': 'poly'}. However, this model identified all observations as Class 1 and was not useful (while recall of Class 1 was 1, there were 0 true negatives; all false positives). The grid search was re-ran without kernel=poly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 66 candidates, totalling 198 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 198 out of 198 | elapsed: 10.7min finished\n"
     ]
    }
   ],
   "source": [
    "# grid search, fit with best estimator\n",
    "gs_svc = GridSearchCV(estimator=SVC(random_state=8), param_grid=parameters, iid=False, cv=3, scoring='recall', n_jobs=-1, verbose=1)\n",
    "gs_svc.fit(X_train_f, y_train_res)\n",
    "y_pred_gssvc = gs_svc.predict(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 20\n",
      "\n",
      "Best hyperparameters: {'C': 10000.0, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "\n",
      "Best tuned estimator:\n",
      "SVC(C=10000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.005, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=8, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "\n",
      "Best mean CV score: 0.995\n",
      "\n",
      "Confusion Matrix:\n",
      "[[270  23]\n",
      " [ 16   5]]\n",
      "\n",
      "TP, TN, FP, FN: 5 , 270 , 23 , 16\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.92      0.93       293\n",
      "         1.0       0.18      0.24      0.20        21\n",
      "\n",
      "    accuracy                           0.88       314\n",
      "   macro avg       0.56      0.58      0.57       314\n",
      "weighted avg       0.89      0.88      0.88       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# features: {}'.format(X_train_f.shape[1]))\n",
    "\n",
    "# best tuned estimator and hyperparameters\n",
    "print('\\nBest hyperparameters: {}'.format(gs_svc.best_params_))\n",
    "print('\\nBest tuned estimator:\\n{}'.format(gs_svc.best_estimator_))\n",
    "print('\\nBest mean CV score: {:.3f}'.format(gs_svc.best_score_))\n",
    "\n",
    "# evaluate model using confusion matrix-derived metrics\n",
    "print ('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_gssvc)) \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_gssvc).ravel()\n",
    "print ('\\nTP, TN, FP, FN:', tp, ',', tn, ',', fp, ',', fn)\n",
    "print ('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred_gssvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above (tuned SVC with feature selection using ANOVA F-value) for comparison across models\n",
    "precision_s, recall_s, fscore_s, support_s = precision_recall_fscore_support(y_test, y_pred_gssvc)\n",
    "accuracy_s = accuracy_score(y_test, y_pred_gssvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary for SVM:\n",
    "<ul>\n",
    "    <li>SVC (default parameters) using all features did not work (no true positives)</li>\n",
    "    <li>SVC (default parameters) and feature selection using ANOVA F-value produced the best result, as assessed by the recall of Class 1 on the test set</li>\n",
    "    <li>However, after hyperparameter tuning recall of Class 1 on the test set did not improve (although overall accuracy did)</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Evaluate all three models\n",
    "Please see above sections for evaluation and summary of the decision tree, ensemble (random forest), and SVM models.<br>\n",
    "All models were evaluated by confusion matrix-derived metrics, primarily by recall of Class 1 (to detect faulty products) and were tuned accordingly.<p>\n",
    "[Evaluation of decision tree model](#DT)<br>\n",
    "[Evaluation of ensemble model (random forest)](#RF)<br>\n",
    "[Evaluation of SVM model](#SVM)\n",
    "\n",
    "\n",
    "The table (dataframe) below compares results from tuned decision tree, random forest, and SVM models using the same feature set (20 features selected using ANOVA F-value)\n",
    "<ul>\n",
    "    <li>Based on Class 1 recall: decision tree > random forest > SVM</li>\n",
    "    <li>Based on Class 1 f1-score: random forest > SVM > decision tree</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>Overall accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.136</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.280</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision  Recall  f1-score  Overall accuracy\n",
       "Decision Tree      0.136   0.381     0.200             0.796\n",
       "Random Forest      0.280   0.333     0.304             0.898\n",
       "SVM                0.179   0.238     0.204             0.876"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Decision Tree': np.round([precision_t[1], recall_t[1], fscore_t[1], accuracy_t],3),\n",
    "              'Random Forest': np.around([precision_r[1], recall_r[1], fscore_r[1], accuracy_r],3),\n",
    "              'SVM': np.round([precision_s[1], recall_s[1], fscore_s[1], accuracy_s],3)\n",
    "             }, index=['Precision', 'Recall', 'f1-score', 'Overall accuracy'])\n",
    "results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Describe your findings\n",
    "##### Results summary:\n",
    "<ul>\n",
    "    <li>From Milestone 1, preprocessing was performed (435 features remained after preprocessing) and class imbalance was handled by applying SMOTE on the training set</li>\n",
    "    <li>Filtering methods based on Mutual information score or ANOVA F-value between label/feature were used to reduce dimensionality of the data (20 features were selected using each scoring method)</li>\n",
    "    <p><p>\n",
    "    <li>Decision tree, ensemble (here, random forest), and SVM models were constructed to detect faulty products </li>\n",
    "        <li>Generally, the 3 models worked best with 20 selected features by ANOVA F-value (as assessed by recall on Class 1 to detect faulty products</li>\n",
    "        <li>After hyperparameter tuning, recall for Class 1 was slightly increased for the decision tree and random forest models but not the SVM</li><p>\n",
    "        <li>Comparing the 3 model types:\n",
    "            <ul>\n",
    "                <li>Based on Class 1 recall: decision tree > random forest > SVM</li>\n",
    "                <li>Based on Class 1 f1-score (taking into account precision): random forest > SVM > decision tree</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>None of the 3 models tested here produced a high recall for Class 1; the highest was ~40%. Additional models (e.g. different ensemble models, neural network) and dimensional reduction techniques (e.g. PCA, foward/backward selection) could be tested</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
